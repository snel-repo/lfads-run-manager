# Setting up a single-session LFADS run

Assuming you have finished [adapting the LFADS run manager classes to your dataset](interfacing), you should be all set to generate some LFADS runs and start training. We'll be setting up a _drive script_ that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling `lfads-run-manager` to generate the files needed for LFADS. Below, we'll refer to the package name as `MyExperiment`, but you should substitute this with your package name.

!!! tip "Follow along with `MyExperiment.drive_script`"
    A complete drive script is available as a starting point in `+MyExperiment/drive_script.m` for you to copy/paste from.


## Lorenz attractor example
For this demo, we'll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code:

```matlab
datasetPath = '~/lorenz_example/datasets';
LFADS.Utils.generateDemoDatasets(datasetPath, 'nDatasets', 3);
```

This will simulate a chaotic 3 dimensional [Lorenz attractor](https://en.wikipedia.org/wiki/Lorenz_system) as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions' trajectories:

![Lorenz trajectories for 10 conditions](images/lorenz_10conditions.png)

From these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the _conditions_) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25--35). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition.

Here are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:

![Example single trial spike rasters](images/raster_examples.png)

## Building a dataset collection and adding datasets

First, create a dataset collection that points to a folder on disk where datasets are stored:

```matlab
dataPath = '~/lorenz_example/datasets';
dc = MyExperiment.DatasetCollection(dataPath);
dc.name = 'lorenz_example';
```

Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the `DatasetCollection` and will replace any dataset that has the same name if present.

```matlab
MyExperiment.Dataset(dc, 'dataset001.mat');
MyExperiment.Dataset(dc, 'dataset002.mat');
MyExperiment.Dataset(dc, 'dataset003.mat');
```

!!! tip "Auto-detecting datasets"
    You might consider adding a method to your `DatasetCollection` class which can automatically detect all of the datasets in a specific folder. An example, which would add every `.mat` file detected in the folder might look like this:

    ```matlab
    function autoDetectDatasets(dc)
        dc.clearDatasets(); % in case there are existing datasets already added

        % automatically find all .mat files within dc.path and build datasets for each
        files = dir(dc.path);
        for iF = 1:numel(files)
            if strncmp(files(iF).name, '.', 1), continue, end
            info = files(iF);
            [~, ~, ext] = fileparts(info.name);
            if ~strcmp(ext, '.mat'), continue; end
            ds = MyExperiment.Dataset(dc, info.name); % change this to match your package name
        end
    end
    ```

You can verify that the datasets have been added to the collection:

```matlab
>> dc
MyExperiment.DatasetCollection "lorenz_example"
  3 datasets in ~/lorenz_example/datasets
  [ 1] MyExperiment.Dataset "dataset001"
  [ 2] MyExperiment.Dataset "dataset002"
  [ 3] MyExperiment.Dataset "dataset003"

         name: 'lorenz_example'
      comment: ''
         path: '~/lorenz_example/datasetss'
     datasets: [3x1 LorenzExperiment.Dataset]
    nDatasets: 3
```

You can access individual datasets using `:::matlab dc.datasets(1)` or by name with `:::matlab dc.matchDatasetsByName('dataset001')`.

You can then load all of the metadata for the datasets using:
```matlab
dc.loadInfo();
```

and view a summary of the results using:

```matlab
>> dc.getDatasetInfoTable          

                  subject                  date             saveTags    nTrials    nChannels
              ________________    ______________________    ________    _______    _________

dataset001    'lorenz_example'    [01-Feb-2017 00:00:00]    '1'         1820       35
dataset002    'lorenz_example'    [01-Feb-2017 00:00:00]    '1'         1885       26
dataset003    'lorenz_example'    [01-Feb-2017 00:00:00]    '1'         1365       35

```

## Create a `RunCollection`

We'll now setup a `RunCollection` that will contain all of the LFADS runs we'll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.

```matlab
runRoot = '~/lorenz_example/runs';
rc_ds1 = MyExperiment.RunCollection(runRoot, 'exampleSingleRun', dc);
rc_ds1.version = 20180206; % replace with approximate data authored as YYYYMMDD
```

!!! tip "Versioning and backwards compatibility"
    You can optionally set `rc.version` just after creating the `RunCollection`. Version should be set to the date the script was first used to generate the LFADS files on disk, in the format `YYYYMMDD`. Specifying this here allows for backwards compatibility in case we need to change aspects of where lfads-run-manager organizes files on disk or how the `RunParams` hashes are generated. The default `rc.version` will be updated if significant changes are made in the code, so manually specifying it in the drive script can be useful to "freeze" the lfads-run-manager logic for this specific collection of runs.

## Specify the hyperparameters in `RunParams`

We'll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we'll reduce the size of the generator network to 64 and reduce the number of factors to 8.

```matlab
par = MyExperiment.RunParams;
par.name = 'first_attempt'; % completely optional
par.spikeBinMs = 2; % rebin the data at 2 ms
par.c_co_dim = 0; % no controller --> no inputs to generator
par.c_batch_size = 150; % must be < 1/5 of the min trial count
par.c_factors_dim = 8; % and manually set it for multisession stitched models
par.c_gen_dim = 64; % number of units in generator RNN
par.c_ic_enc_dim = 64; % number of units in encoder RNN
par.c_learning_rate_stop = 1e-3; % we can stop training early for the demo
```

!!! warning "Setting batch size"
      The number of trials in your smallest dataset determines the largest batch size you can pick. If `trainToTestRatio` is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as `c_batch_size`. If you choose a batch size which is too large, `lfads-run-manager` will generate an error to alert you.

We then add this `RunParams` to the `RunCollection`:

```matlab
rc.addParams(par);
```

You can access the parameter settings added to `rc` using `rc.params`, which will be an array of `RunParams` instances.

### `RunParams` data and param hashes

If we look at the printed representation of the `RunParams` instance, we see two hash values:

```matlab
>> par

par =

MyExperiment.RunParams param_YOs74u data_4MaTKO
c_factors_dim=8 c_ic_enc_dim=64 c_gen_dim=64 c_co_dim=0 c_batch_size=150 c_learning_rate_stop=0.001
...
```

These six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. The first is the "param" hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with `param_`.  The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by `data_`. We use two separate hashes here to save space on disk; many parameters like `c_co_dim` only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like `c_co_dim` would otherwise require many copies of identical data to be saved on disk. Intead, we store the data in folders according to the `data_` hash and symlink copies for each run.

Below the hash values are the set of properties whose values differ from their specified defaults (as specified next to the property in the class definition). Properties which are equal to their default values are not included in the hash calculation. This allows you to add new properties to your `RunParams` class without altering the computed hashes for older runs. See this [warning note](interfacing/#editing-runparamsm-optional) for more details.

!!! tip "Specifying data-hash affecting parameters"
    By default, the `data_` hash includes all properties that do not begin with `c_` as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to `RunParams`. If you need to adjust this behavior, override the method `getListPropertiesNotAffectingInputData` in your `RunParams` instance. You should probably take a union of your custom properties with the properties returned by the superclass method `:::matlab LFADS.Run/getListPropertiesNotAffectingInputData`.

!!! tip "`RunParams` is a value class"
    Unlike all of the other classes, `RunParams` is not a handle but a value class, which acts similarly to a `struct` in that it is passed by value. This means that after adding the `RunParams` instance `par` to the `RunCollection`, we can modify `par` and then add it again to define a second set of parameters, like this:
    ```matlab
    par.c_gen_dim = 96;
    rc.addParams(par);
    par.c_gen_dim = 128;
    rc.addParams(par);
    ```

!!! tip "Generating hyperparameter value sweeps"
    If you wish to sweep a specific property or set of properties, you can create a `RunParams` instance, set the other properties as needed, and then call `generateSweep` to build an array of `RunParams` instances:
    ```matlab
    parSet = par.generateSweep('c_gen_dim', [32 64 96 128]);
    rc.addParams(parSet);
    ```

    Or along multiple parameters in a grid:
    ```matlab
    parSet = par.generateSweep('c_gen_dim', [32 64 96 128], 'c_co_dim', 0:2:4);
    rc.addParams(parSet);
    ```

## Specify the `RunSpec`

Recall that `RunSpec` instances specify which datasets are included in a specific run. We'll start by setting up a single dataset run for the first dataset:

```matlab
ds_index = 1;
runSpecName = dc.datasets(ds_index).getSingleRunName(); % generates a simple run name from this datasets name
runSpec = LorenzExperiment.RunSpec(runSpecName, dc, ds_index);
```

You can adjust the arguments to the constructor of `MyExperiment.RunSpec`, but in the example provided the inputs define:

* the unique name of the run. Here we use `getSingleRunName`, a convenience method of `Dataset` that generates a name like `single_datasetName`.
* the `DatasetCollection` from which datasets will be retrieved
* the indices or names of datasets (as a string or cell array of strings) to include

## Check the `RunCollection`

The `RunCollection` will now display inforation about the parameter settings and run specifications that have been added:

```matlab
>> rc

LorenzExperiment.RunCollection "exampleSingleSession" (1 runs total)
  Dataset Collection "lorenz_example" (3 datasets) in ~/lorenz_example/datasets
  Path: ~/lorenz_example/runs/exampleSingleSession

  1 parameter settings
  [1 param_YOs74u data_4MaTKO] LorenzExperiment.RunParams "first_attempt" c_factors_dim=8 c_ic_enc_dim=64 c_gen_dim=64 c_co_dim=0 c_batch_size=150 c_learning_rate_stop=0.001

  1 run specifications
  [ 1] LorenzExperiment.RunSpec "single_dataset001" (1 datasets)

                          name: 'exampleSingleSession'
                       comment: ''
                      rootPath: '~/lorenz_example/runs'
                       version: 20180206
             datasetCollection: [1x1 LorenzExperiment.DatasetCollection]
                          runs: [1x1 LorenzExperiment.Run]
                        params: [1x1 LorenzExperiment.RunParams]
                      runSpecs: [1x1 LorenzExperiment.RunSpec]
                       nParams: 1
                     nRunSpecs: 1
                    nRunsTotal: 1
                     nDatasets: 3
                  datasetNames: {3x1 cell}
                          path: '~/lorenz_example/runs/exampleSingleSession'
      pathsCommonDataForParams: {'~/lorenz_example/runs/exampleSingleSession/data_4MaTKO'}
                pathsForParams: {'~/lorenz_example/runs/exampleSingleSession/param_YOs74u'}
    fileShellScriptTensorboard: '~/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh'
               fileSummaryText: '~/lorenz_example/runs/exampleSingleSession/summary.txt'
       fileShellScriptRunQueue: '~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py'

```

## Prepare for LFADS

Now that you've set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.

```matlab
rc.prepareForLFADS();
```

This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call `prepareForLFADS` again. Existing files won't be overwritten unless you call `rc.prepareForLFADS(true)`.

After running `prepareForLFADS`, the run manager will create the following files on disk under `rc.path`:

```bash
~/lorenz_example/runs/exampleSingleSession
├── data_4MaTKO
│   └── single_dataset001
│       ├── inputInfo_dataset001.mat
│       └── lfads_dataset001.h5
├── param_YOs74u
│   └── single_dataset001
│       └── lfadsInput
│           ├── inputInfo_dataset001.mat -> ../../../data_4MaTKO/single_dataset001/inputInfo_dataset001.mat
│           └── lfads_dataset001.h5 -> ../../../data_4MaTKO/single_dataset001/lfads_dataset001.h5
└── summary.txt
```

The organization of these files on disk is discussed in more detail [here](files.md). Also, a `summary.txt` file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling `rc.generateSummaryText()`.

```
LorenzExperiment.RunCollection "exampleSingleSession" (1 runs total)
  Path: ~/lorenz_example/runs/exampleSingleSession
  Dataset Collection "lorenz_example" (3 datasets) in ~/lorenz_example/datasets

  ------------------------

  1 Run Specifications:

    [runSpec 1] LorenzExperiment.RunSpec "single_dataset001" (1 datasets)
      [ds 1] LorenzExperiment.Dataset "dataset001"

  ------------------------

  1 Parameter Settings:

    [1 param_YOs74u data_4MaTKO] LorenzExperiment.RunParams "first_attempt"
      c_factors_dim=8 c_ic_enc_dim=64 c_gen_dim=64 c_co_dim=0 c_batch_size=150 c_learning_rate_stop=0.001

      spikeBinMs: 2
      trainToTestRatio: 4
      useAlignmentMatrix: false
      useSingleDatasetAlignmentMatrix: false
      scaleIncreaseStepsWithDatasets: true
      c_cell_clip_value: 5
      c_factors_dim: 8
      c_ic_enc_dim: 64
      c_ci_enc_dim: 128
      c_gen_dim: 64
      c_keep_prob: 0.95
      c_learning_rate_decay_factor: 0.98
      c_device: /gpu:0
      c_co_dim: 0
      c_do_causal_controller: false
      c_do_feed_factors_to_controller: true
      c_feedback_factors_or_rates: factors
      c_controller_input_lag: 1
      c_do_train_readin: true
      c_l2_gen_scale: 500
      c_l2_con_scale: 500
      c_batch_size: 150
      c_kl_increase_steps: 900
      c_l2_increase_steps: 900
      c_ic_dim: 64
      c_con_dim: 128
      c_learning_rate_stop: 0.001
      c_temporal_spike_jitter_width: 0
      c_allow_gpu_growth: true
      c_kl_ic_weight: 1
      c_kl_co_weight: 1
      c_inject_ext_input_to_gen: false
      num_samples_posterior: 512
```
